"""
ğŸ¬ Ollamaå®¢æˆ·ç«¯æ¨¡å—
ä¸æœ¬åœ°OllamaæœåŠ¡äº¤äº’è¿›è¡ŒAIæ–‡æ¡ˆæ”¹å†™
"""

import logging
import json
import time
import requests
from typing import Dict, Any, Optional, Union, Callable
from .config import CONFIG
from .utils import SystemUtils

logger = logging.getLogger(__name__)

class OllamaClient:
    """Ollamaå®¢æˆ·ç«¯"""

    def __init__(self):
        self.api_url = CONFIG.get('ollama.url', 'http://localhost:11434/api/generate')
        self.model = CONFIG.get('ollama.model', 'deepseek-r1:8b')
        self.timeout = CONFIG.get('ollama.timeout', 600)
        self.max_retries = CONFIG.get('ollama.max_retries', 3)
        self.retry_delay = CONFIG.get('ollama.retry_delay', 2)
        self.stream = CONFIG.get('ollama.stream', False)
        self.system_prompt = CONFIG.get('ollama.system_prompt', '')
        self.default_options = {
            # ä¼˜å…ˆä»é…ç½®è¯»å–ï¼Œå›é€€åˆ°å®‰å…¨ä½å†…å­˜å€¼
            'num_ctx': CONFIG.get('ollama.options.num_ctx', 1024),
            'num_predict': CONFIG.get('ollama.options.num_predict', 512),
            'temperature': CONFIG.get('ollama.options.temperature', 0.7),
            'top_p': CONFIG.get('ollama.options.top_p', 0.9),
            'top_k': CONFIG.get('ollama.options.top_k', 40),
            'num_thread': CONFIG.get('advanced.cpu_threads', 4)
        }

        logger.info(f"ğŸ¦™ Ollamaå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ (æ¨¡å‹: {self.model})")

    def test_connection(self) -> Dict[str, Any]:
        """æµ‹è¯•OllamaæœåŠ¡è¿æ¥"""
        try:
            # æµ‹è¯•æœåŠ¡åŸºæœ¬è¿æ¥
            response = requests.get(
                'http://localhost:11434',
                timeout=5
            )

            if response.status_code == 200:
                # è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
                models_response = self._make_request(
                    'http://localhost:11434/api/tags',
                    method='GET'
                )

                if models_response.get('success'):
                    models = models_response.get('data', {}).get('models', [])
                    available_models = [model['name'] for model in models]

                    return {
                        'success': True,
                        'connected': True,
                        'available_models': available_models,
                        'current_model': self.model,
                        'model_available': self.model in available_models
                    }
                else:
                    return {
                        'success': True,
                        'connected': True,
                        'available_models': [],
                        'current_model': self.model,
                        'model_available': False,
                        'warning': 'æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨'
                    }
            else:
                return {
                    'success': False,
                    'connected': False,
                    'error': f'OllamaæœåŠ¡å“åº”å¼‚å¸¸: {response.status_code}'
                }

        except requests.exceptions.ConnectionError:
            return {
                'success': False,
                'connected': False,
                'error': 'æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡ï¼Œè¯·ç¡®è®¤æœåŠ¡æ­£åœ¨è¿è¡Œ'
            }
        except requests.exceptions.Timeout:
            return {
                'success': False,
                'connected': False,
                'error': 'è¿æ¥OllamaæœåŠ¡è¶…æ—¶'
            }
        except Exception as e:
            return {
                'success': False,
                'connected': False,
                'error': f'è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}'
            }

    def rewrite_text(
        self,
        original_text: str,
        model: str = None,
        system_prompt: str = None,
        progress_callback: Callable = None
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨AIæ”¹å†™æ–‡æ¡ˆ

        Args:
            original_text: åŸå§‹æ–‡æ¡ˆ
            model: ä½¿ç”¨çš„æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°

        Returns:
            æ”¹å†™ç»“æœå­—å…¸
        """
        try:
            # éªŒè¯è¾“å…¥
            if not original_text or not original_text.strip():
                return {
                    'success': False,
                    'error': 'åŸå§‹æ–‡æ¡ˆä¸èƒ½ä¸ºç©º',
                    'rewritten_text': None
                }

            # ä½¿ç”¨é»˜è®¤å€¼
            model = model or self.model
            system_prompt = system_prompt or self.system_prompt

            logger.info(f"ğŸ¦™ å¼€å§‹AIæ–‡æ¡ˆæ”¹å†™ (æ¨¡å‹: {model})")
            logger.debug(f"åŸå§‹æ–‡æ¡ˆé•¿åº¦: {len(original_text)} å­—ç¬¦")

            # æµ‹è¯•è¿æ¥
            connection_test = self.test_connection()
            if not connection_test['success']:
                return connection_test

            if not connection_test.get('model_available', True):
                logger.warning(f"æ¨¡å‹ {model} ä¸å¯ç”¨")

            # æ„å»ºè¯·æ±‚å‚æ•°ï¼ˆç¡®ä¿ä»…è¾“å‡ºä»¿å†™æ–‡æ¡ˆï¼‰
            request_data = {
                'model': model,
                'prompt': (
                    "è¯·ä¸¥æ ¼æ ¹æ®ç³»ç»Ÿæç¤ºè¯è¿›è¡Œä»¿å†™ã€‚\n"
                    "è¦æ±‚ï¼šåªè¾“å‡ºä»¿å†™åçš„æ–‡æ¡ˆï¼Œä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæˆ–å¤šä½™å†…å®¹ã€‚\n"
                    f"åŸæ–‡å¦‚ä¸‹ï¼š\n{original_text}\n"
                ),
                'system': system_prompt,
                'stream': self.stream,
                'options': dict(self.default_options)
            }

            if progress_callback:
                progress_callback(10, "å‡†å¤‡AIæ”¹å†™...")
                progress_callback(30, "å‘é€è¯·æ±‚åˆ°Ollama...")

            # å‘é€è¯·æ±‚
            response = self._make_request_with_retry(
                self.api_url,
                method='POST',
                data=request_data,
                progress_callback=progress_callback
            )

            # é’ˆå¯¹å†…å­˜å¸ƒå±€é”™è¯¯è¿›è¡Œä¸€æ¬¡è‡ªåŠ¨é™é…é‡è¯•
            if (not response.get('success')) and isinstance(response.get('error'), str) and (
                'memory layout cannot be allocated' in response['error'] or
                'unable to allocate' in response['error']
            ):
                logger.warning("æ£€æµ‹åˆ°å†…å­˜å¸ƒå±€åˆ†é…å¤±è´¥ï¼Œè‡ªåŠ¨é™é…é‡è¯•ï¼šå‡å°ä¸Šä¸‹æ–‡ä¸é¢„æµ‹é•¿åº¦")
                # é™ä½ä¸Šä¸‹æ–‡ä¸é¢„æµ‹é•¿åº¦
                request_data['options']['num_ctx'] = max(512, int(request_data['options'].get('num_ctx', 1024) / 2))
                request_data['options']['num_predict'] = max(256, int(request_data['options'].get('num_predict', 512) / 2))
                # å†æ¬¡å°è¯•
                response = self._make_request_with_retry(
                    self.api_url,
                    method='POST',
                    data=request_data,
                    progress_callback=progress_callback
                )

            # è‹¥ä»å¤±è´¥ä¸”æ˜ç¡®ä¸ºå†…å­˜é”™è¯¯ï¼Œå°è¯•æ›´å°æ¨¡å‹ä¸€æ¬¡
            if (not response.get('success')) and isinstance(response.get('error'), str) and (
                'memory layout cannot be allocated' in response['error'] or
                'unable to allocate' in response['error']
            ):
                fallback_model = 'qwen2:1.5b'
                logger.warning(f"å½“å‰æ¨¡å‹ {model} å†…å­˜ä¸è¶³ï¼Œå°è¯•æ›´å°æ¨¡å‹: {fallback_model}")
                request_data['model'] = fallback_model
                response = self._make_request_with_retry(
                    self.api_url,
                    method='POST',
                    data=request_data,
                    progress_callback=progress_callback
                )
                # å¦‚æœè¿”å›404æ¨¡å‹ä¸å­˜åœ¨ï¼Œåˆ™è‡ªåŠ¨æ‹‰å–å¹¶é‡è¯•ä¸€æ¬¡
                if (not response.get('success')) and str(response.get('error', '')).startswith('HTTP 404'):
                    if progress_callback:
                        progress_callback(35, f"æœªæ‰¾åˆ°æ¨¡å‹ {fallback_model}ï¼Œå¼€å§‹æ‹‰å–...")
                    pull_resp = self._pull_model(fallback_model, progress_callback)
                    if pull_resp.get('success'):
                        logger.info(f"æ¨¡å‹ {fallback_model} æ‹‰å–å®Œæˆï¼Œé‡è¯•ç”Ÿæˆ")
                        response = self._make_request_with_retry(
                            self.api_url,
                            method='POST',
                            data=request_data,
                            progress_callback=progress_callback
                        )
                    else:
                        logger.warning(f"æ¨¡å‹æ‹‰å–å¤±è´¥: {pull_resp.get('error')}")

            if progress_callback:
                progress_callback(90, "å¤„ç†AIå“åº”...")

            # å¤„ç†å“åº”
            if response['success']:
                rewritten_text = self._extract_text_from_response(response['data'])
                rewritten_text = self._cleanup_output(rewritten_text).strip()
                rewritten_text = self._ensure_same_opening(original_text, rewritten_text)

                if not rewritten_text:
                    return {
                        'success': False,
                        'error': 'AIæœªç”Ÿæˆæ”¹å†™å†…å®¹',
                        'rewritten_text': None
                    }

                logger.info(f"âœ… AIæ–‡æ¡ˆæ”¹å†™æˆåŠŸï¼Œç”Ÿæˆå­—æ•°: {len(rewritten_text)}")

                return {
                    'success': True,
                    'rewritten_text': rewritten_text,
                    'original_text': original_text,
                    'model_used': model,
                    'original_length': len(original_text),
                    'rewritten_length': len(rewritten_text),
                    'processing_time': response.get('processing_time', 0)
                }
            else:
                return response

        except Exception as e:
            logger.error(f"âŒ AIæ–‡æ¡ˆæ”¹å†™å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e),
                'rewritten_text': None
            }

    def _extract_text_from_response(self, response_data: Dict[str, Any]) -> str:
        """ä»å“åº”ä¸­æå–æ–‡æœ¬å†…å®¹"""
        try:
            # å¤„ç†deepseek-r1:8bç­‰æ¨¡å‹çš„ç‰¹æ®Šå“åº”æ ¼å¼
            if isinstance(response_data, dict):
                # æ£€æŸ¥æ˜¯å¦æœ‰responseå­—æ®µ
                if 'response' in response_data:
                    response_text = response_data['response']
                    # å¦‚æœresponseä¸ä¸ºç©ºï¼Œç›´æ¥è¿”å›
                    if response_text and response_text.strip():
                        return response_text

                # å¦‚æœæ²¡æœ‰responseå­—æ®µï¼Œå°è¯•å…¶ä»–å¯èƒ½çš„å­—æ®µ
                possible_fields = ['text', 'content', 'generated_text', 'output']
                for field in possible_fields:
                    if field in response_data:
                        value = response_data[field]
                        if value and str(value).strip():
                            return str(value)

                # å¦‚æœéƒ½æ²¡æœ‰ï¼Œå°è¯•ä»å…¶ä»–å­—æ®µæå–æ–‡æœ¬
                for key, value in response_data.items():
                    if key not in ['model', 'created_at', 'done', 'done_reason', 'context', 'total_duration', 'load_duration', 'prompt_eval_count', 'prompt_eval_duration', 'eval_count', 'eval_duration', 'thinking'] and isinstance(value, str) and value.strip():
                        return value

                # æœ€åçš„å¤‡é€‰æ–¹æ¡ˆï¼šè¿”å›æ‰€æœ‰å­—ç¬¦ä¸²å­—æ®µçš„ç»„åˆ
                text_parts = []
                for key, value in response_data.items():
                    if isinstance(value, str) and value.strip():
                        text_parts.append(value)
                if text_parts:
                    return ' '.join(text_parts)

            elif isinstance(response_data, str):
                return response_data
            elif isinstance(response_data, list):
                # å¤„ç†æµå¼å“åº”çš„åˆ—è¡¨æ ¼å¼
                return ''.join(item.get('response', '') if isinstance(item, dict) else str(item) for item in response_data)
            else:
                return str(response_data)

        except Exception as e:
            logger.warning(f"å“åº”æ–‡æœ¬æå–å¤±è´¥: {e}")
            logger.debug(f"å“åº”æ•°æ®: {response_data}")
            return str(response_data)

    def _cleanup_output(self, text: str) -> str:
        """æ¸…ç†æ¨¡å‹è¾“å‡ºä¸­çš„å¤šä½™æ ‡ç­¾æˆ–å‰ç¼€ï¼Œä¿ç•™çº¯ä»¿å†™æ–‡æ¡ˆ"""
        try:
            cleaned = text.strip()
            # å»é™¤å¸¸è§å‰ç¼€
            prefixes = [
                "ä»¿å†™ï¼š", "ä»¿å†™æ–‡æ¡ˆï¼š", "æ”¹å†™ï¼š", "æ”¹å†™æ–‡æ¡ˆï¼š",
                "ä»¥ä¸‹æ˜¯ä»¿å†™åçš„æ–‡æ¡ˆï¼š", "ä»¥ä¸‹ä¸ºä»¿å†™ç»“æœï¼š",
                "ç»“æœï¼š", "è¾“å‡ºï¼š"
            ]
            for p in prefixes:
                if cleaned.startswith(p):
                    cleaned = cleaned[len(p):].strip()
                    break
            return cleaned
        except Exception:
            return text

    def _ensure_same_opening(self, original_text: str, rewritten_text: str) -> str:
        """ç¡®ä¿ä»¿å†™æ–‡æ¡ˆçš„å¼€å¤´ä¸åŸæ–‡ä¸€è‡´ï¼ˆæŒ‰é¦–å¥æˆ–é¦–è¡ŒåŒ¹é…ï¼‰"""
        try:
            orig = original_text.strip()
            rew = rewritten_text.strip()

            if not orig or not rew:
                return rew

            # æå–åŸæ–‡é¦–å¥/é¦–è¡Œ
            delimiters = ['ã€‚', 'ï¼', 'ï¼Ÿ', '\n']
            cut_idx = None
            for d in delimiters:
                i = orig.find(d)
                if i != -1:
                    cut_idx = i + len(d)
                    break
            orig_opening = orig[:cut_idx] if cut_idx else orig.split('\n', 1)[0]

            # å¦‚æœä»¿å†™ä¸ä»¥åŸå§‹å¼€å¤´å¼€å§‹ï¼Œåˆ™å¼ºåˆ¶å‰ç½®
            if not rew.startswith(orig_opening):
                rew = f"{orig_opening}{rew}"

            return rew
        except Exception:
            return rewritten_text

    def _make_request_with_retry(
        self,
        url: str,
        method: str = 'POST',
        data: Dict[str, Any] = None,
        progress_callback: Callable = None
    ) -> Dict[str, Any]:
        """å¸¦é‡è¯•æœºåˆ¶çš„è¯·æ±‚"""
        last_error = None

        for attempt in range(self.max_retries):
            try:
                if progress_callback:
                    progress_callback(50, f"AIå¤„ç†ä¸­... (å°è¯• {attempt + 1}/{self.max_retries})")

                start_time = time.time()
                response = self._make_request(url, method, data)

                processing_time = time.time() - start_time

                if response['success']:
                    response['processing_time'] = processing_time
                    return response
                else:
                    last_error = response.get('error', 'æœªçŸ¥é”™è¯¯')

            except Exception as e:
                last_error = str(e)
                logger.warning(f"è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{self.max_retries}): {e}")

            # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…é‡è¯•
            if attempt < self.max_retries - 1:
                wait_time = self.retry_delay * (2 ** attempt)  # æŒ‡æ•°é€€é¿
                logger.info(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)

        return {
            'success': False,
            'error': f'è¯·æ±‚å¤±è´¥ï¼Œå·²é‡è¯• {self.max_retries} æ¬¡: {last_error}'
        }

    def _make_request(
        self,
        url: str,
        method: str = 'POST',
        data: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """å‘é€HTTPè¯·æ±‚"""
        try:
            if method.upper() == 'GET':
                response = requests.get(url, timeout=self.timeout)
            elif method.upper() == 'POST':
                response = requests.post(
                    url,
                    json=data,
                    timeout=self.timeout,
                    headers={'Content-Type': 'application/json'}
                )
            else:
                return {
                    'success': False,
                    'error': f'ä¸æ”¯æŒçš„HTTPæ–¹æ³•: {method}'
                }

            if response.status_code == 200:
                return {
                    'success': True,
                    'data': response.json(),
                    'status_code': response.status_code
                }
            else:
                return {
                    'success': False,
                    'error': f'HTTP {response.status_code}: {response.text}',
                    'status_code': response.status_code
                }

        except requests.exceptions.Timeout:
            return {
                'success': False,
                'error': 'è¯·æ±‚è¶…æ—¶'
            }

    def _pull_model(self, model_name: str, progress_callback: Callable = None) -> Dict[str, Any]:
        """æ‹‰å–æŒ‡å®šæ¨¡å‹ï¼ˆå¦‚æœæœªå®‰è£…ï¼‰"""
        try:
            response = requests.post(
                'http://localhost:11434/api/pull',
                json={'name': model_name},
                timeout=self.timeout,
                headers={'Content-Type': 'application/json'}
            )
            if response.status_code == 200:
                return {
                    'success': True,
                    'data': response.json(),
                    'status_code': response.status_code
                }
            else:
                return {
                    'success': False,
                    'error': f'HTTP {response.status_code}: {response.text}',
                    'status_code': response.status_code
                }
        except Exception as e:
            return {
                'success': False,
                'error': f'æ‹‰å–æ¨¡å‹å¼‚å¸¸: {str(e)}'
            }
        except requests.exceptions.ConnectionError:
            return {
                'success': False,
                'error': 'è¿æ¥é”™è¯¯'
            }
        except requests.exceptions.JSONDecodeError:
            return {
                'success': False,
                'error': 'å“åº”JSONè§£æå¤±è´¥'
            }
        except Exception as e:
            return {
                'success': False,
                'error': f'è¯·æ±‚å¼‚å¸¸: {str(e)}'
            }

    def get_available_models(self) -> Dict[str, Any]:
        """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
        try:
            response = self._make_request(
                'http://localhost:11434/api/tags',
                method='GET'
            )

            if response['success']:
                models = response.get('data', {}).get('models', [])
                model_info = []

                for model in models:
                    model_info.append({
                        'name': model.get('name'),
                        'size_mb': model.get('size', 0) / (1024 * 1024),
                        'modified_at': model.get('modified_at'),
                        'digest': model.get('digest')[:12]  # æ˜¾ç¤ºå‰12ä½
                    })

                return {
                    'success': True,
                    'models': model_info,
                    'total_models': len(model_info)
                }
            else:
                return response

        except Exception as e:
            return {
                'success': False,
                'error': f'è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}'
            }

    def get_model_info(self, model_name: str = None) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        if model_name is None:
            model_name = self.model

        # æ¨¡å‹ä¿¡æ¯æ˜ å°„
        model_specs = {
            'deepseek-r1:8b': {
                'name': 'DeepSeek R1 8B',
                'description': 'ä¸­æ–‡ä¼˜åŒ–ï¼Œé€»è¾‘æ€§å¼ºï¼Œé€‚åˆæ–‡æ¡ˆæ”¹å†™',
                'size_gb': 4.7,
                'recommended': True
            },
            'llama3-chinese:8b': {
                'name': 'Llama3 Chinese 8B',
                'description': 'ä¸­æ–‡å¯¹è¯ï¼Œå“åº”å¿«ï¼Œé€‚åˆå¿«é€Ÿæ”¹å†™',
                'size_gb': 4.7,
                'recommended': True
            },
            'qwen:7b': {
                'name': 'Qwen 7B',
                'description': 'é˜¿é‡Œå‡ºå“ï¼Œä¸­æ–‡ä¼˜ç§€ï¼Œé€‚åˆåˆ›æ„æ–‡æ¡ˆ',
                'size_gb': 4.3,
                'recommended': True
            },
            'qwen:14b': {
                'name': 'Qwen 14B',
                'description': 'å¤§æ¨¡å‹ï¼Œè´¨é‡æ›´é«˜ï¼Œé€‚åˆä¸“ä¸šåˆ›ä½œ',
                'size_gb': 8.3,
                'recommended': True
            },
            'llama3:8b': {
                'name': 'Llama3 8B',
                'description': 'é€šç”¨å¤§æ¨¡å‹ï¼Œå¤šè¯­è¨€æ”¯æŒ',
                'size_gb': 4.7,
                'recommended': False
            }
        }

        return model_specs.get(model_name, {
            'name': model_name,
            'description': 'æœªçŸ¥æ¨¡å‹',
            'size_gb': 0,
            'recommended': False
        })

    def set_model(self, model_name: str) -> bool:
        """è®¾ç½®å½“å‰æ¨¡å‹"""
        try:
            # æµ‹è¯•æ¨¡å‹æ˜¯å¦å­˜åœ¨
            models_response = self.get_available_models()
            if models_response['success']:
                available_models = [model['name'] for model in models_response['models']]
                if model_name not in available_models:
                    logger.warning(f"æ¨¡å‹ {model_name} ä¸åœ¨å¯ç”¨åˆ—è¡¨ä¸­")
                    return False

            self.model = model_name
            logger.info(f"æ¨¡å‹å·²åˆ‡æ¢åˆ°: {model_name}")
            return True

        except Exception as e:
            logger.error(f"è®¾ç½®æ¨¡å‹å¤±è´¥: {e}")
            return False

    def rewrite_with_different_styles(
        self,
        original_text: str,
        styles: list = None,
        progress_callback: Callable = None
    ) -> Dict[str, Any]:
        """ä½¿ç”¨ä¸åŒé£æ ¼æ”¹å†™æ–‡æ¡ˆ"""
        if styles is None:
            styles = [
                "ä¿æŒåŸæœ‰é£æ ¼ï¼Œä½†ä¼˜åŒ–è¡¨è¾¾",
                "æ›´åŠ ç”ŸåŠ¨æœ‰è¶£ï¼Œå¢åŠ æ„ŸæŸ“åŠ›",
                "æ›´åŠ ä¸“ä¸šæ­£å¼ï¼Œçªå‡ºé‡ç‚¹",
                "æ›´åŠ ç®€æ´æ˜äº†ï¼Œä¾¿äºç†è§£"
            ]

        results = []
        total_styles = len(styles)

        for i, style in enumerate(styles):
            try:
                # è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯
                custom_prompt = f"{self.system_prompt}\n\næ”¹å†™é£æ ¼ï¼š{style}"

                if progress_callback:
                    progress = (i / total_styles) * 100
                    progress_callback(progress, f"ç”Ÿæˆé£æ ¼{i+1}/{total_styles}: {style[:20]}...")

                result = self.rewrite_text(
                    original_text,
                    system_prompt=custom_prompt
                )

                if result['success']:
                    results.append({
                        'style': style,
                        'text': result['rewritten_text'],
                        'model': result['model_used'],
                        'processing_time': result['processing_time']
                    })

            except Exception as e:
                logger.error(f"é£æ ¼{i+1}æ”¹å†™å¤±è´¥: {e}")

        if progress_callback:
            progress_callback(100, "å¤šé£æ ¼æ”¹å†™å®Œæˆ")

        return {
            'success': len(results) > 0,
            'original_text': original_text,
            'style_results': results,
            'total_styles': total_styles,
            'successful_styles': len(results)
        }

    def batch_rewrite(
        self,
        texts: list,
        progress_callback: Callable = None
    ) -> Dict[str, Any]:
        """æ‰¹é‡æ”¹å†™æ–‡æ¡ˆ"""
        try:
            results = []
            total_texts = len(texts)

            for i, text in enumerate(texts):
                try:
                    if progress_callback:
                        progress = (i / total_texts) * 100
                        progress_callback(progress, f"æ”¹å†™æ–‡æ¡ˆ {i+1}/{total_texts}")

                    result = self.rewrite_text(text)
                    results.append(result)

                except Exception as e:
                    logger.error(f"æ–‡æ¡ˆ{i+1}æ”¹å†™å¤±è´¥: {e}")

            if progress_callback:
                progress_callback(100, "æ‰¹é‡æ”¹å†™å®Œæˆ")

            successful_results = [r for r in results if r['success']]

            return {
                'success': len(successful_results) > 0,
                'total_texts': total_texts,
                'successful_texts': len(successful_results),
                'results': results,
                'success_rate': len(successful_results) / total_texts if total_texts > 0 else 0
            }

        except Exception as e:
            return {
                'success': False,
                'error': f'æ‰¹é‡æ”¹å†™å¤±è´¥: {str(e)}'
            }

if __name__ == "__main__":
    # æµ‹è¯•Ollamaå®¢æˆ·ç«¯
    print("=== Ollamaå®¢æˆ·ç«¯æµ‹è¯• ===")

    client = OllamaClient()

    # æµ‹è¯•è¿æ¥
    print("\n--- è¿æ¥æµ‹è¯• ---")
    connection = client.test_connection()
    print(f"è¿æ¥çŠ¶æ€: {connection}")

    # è·å–å¯ç”¨æ¨¡å‹
    print("\n--- å¯ç”¨æ¨¡å‹ ---")
    models = client.get_available_models()
    if models['success']:
        for model in models['models']:
            print(f"  {model['name']} - {model['size_mb']:.1f}MB")

    # æ¨¡å‹ä¿¡æ¯
    print("\n--- æ¨¡å‹ä¿¡æ¯ ---")
    info = client.get_model_info()
    print(f"å½“å‰æ¨¡å‹: {info}")

    # æµ‹è¯•æ”¹å†™ï¼ˆå¦‚æœè¿æ¥æˆåŠŸï¼‰
    if connection['success']:
        print("\n--- æ”¹å†™æµ‹è¯• ---")
        test_text = "è¿™æ˜¯ä¸€æ®µæµ‹è¯•æ–‡æ¡ˆï¼Œç”¨æ¥æµ‹è¯•AIæ”¹å†™åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚"
        result = client.rewrite_text(test_text)

        if result['success']:
            print(f"âœ… æ”¹å†™æˆåŠŸ")
            print(f"åŸæ–‡: {test_text}")
            print(f"æ”¹å†™: {result['rewritten_text']}")
        else:
            print(f"âŒ æ”¹å†™å¤±è´¥: {result.get('error')}")
    else:
        print("âŒ è¿æ¥å¤±è´¥ï¼Œè·³è¿‡æ”¹å†™æµ‹è¯•")